{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ffea44",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81712e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5d324",
   "metadata": {},
   "source": [
    "# Generate random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab738bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movies(n_samples=1200, n_frames=15):\n",
    "    row = 80\n",
    "    col = 80\n",
    "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 3), dtype=np.float)\n",
    "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 3), dtype=np.float)\n",
    "\n",
    "    epsilon = np.random.random() / 1000\n",
    "\n",
    "    Y = np.zeros((n_samples, 4), dtype=np.float)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # Add 3 to 7 moving squares\n",
    "        n = np.random.randint(3, 8)\n",
    "\n",
    "        # Direction of motion (All squares are moving in the same direction)\n",
    "        directionx = np.random.choice([-1, 0, 1])\n",
    "        directiony = np.random.choice([-1, 0, 1])\n",
    "\n",
    "        # Make the target smooth\n",
    "        # Section 7 of https://arxiv.org/pdf/1512.00567.pdf\n",
    "        Y[i, ::] = epsilon\n",
    "        if directionx < 0:\n",
    "            Y[i, 0] = 1\n",
    "        if directionx > 0:\n",
    "            Y[i, 1] = 1\n",
    "        if directiony < 0:\n",
    "            Y[i, 2] = 1\n",
    "        if directiony > 0:\n",
    "            Y[i, 3] = 1\n",
    "        Y[i] = Y[i] / np.linalg.norm(Y[i])\n",
    "\n",
    "        for j in range(n):\n",
    "            # Initial position\n",
    "            xstart = np.random.randint(20, 60)\n",
    "            ystart = np.random.randint(20, 60)\n",
    "\n",
    "            directionx *= np.random.randint(1, 3)\n",
    "            directiony *= np.random.randint(1, 3)\n",
    "\n",
    "            # Size of the square\n",
    "            w = np.random.randint(2, 4)\n",
    "\n",
    "            for t in range(n_frames):\n",
    "                x_shift = xstart + directionx * t\n",
    "                y_shift = ystart + directiony * t\n",
    "                noisy_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, ::\n",
    "                ] += 1\n",
    "\n",
    "                # Make it more robust by adding noise.\n",
    "                # The idea is that if during inference,\n",
    "                # the value of the pixel is not exactly one,\n",
    "                # we need to train the network to be robust and still\n",
    "                # consider it as a pixel belonging to a square.\n",
    "                if np.random.randint(0, 2):\n",
    "                    noise_f = (-1) ** np.random.randint(0, 2)\n",
    "                    noisy_movies[\n",
    "                        i,\n",
    "                        t,\n",
    "                        x_shift - w - 1 : x_shift + w + 1,\n",
    "                        y_shift - w - 1 : y_shift + w + 1,\n",
    "                        ::,\n",
    "                    ] += (\n",
    "                        noise_f * 0.1\n",
    "                    )\n",
    "\n",
    "                # Shift the ground truth by 1\n",
    "                x_shift = xstart + directionx * (t + 1)\n",
    "                y_shift = ystart + directiony * (t + 1)\n",
    "                shifted_movies[\n",
    "                    i, t, x_shift - w : x_shift + w, y_shift - w : y_shift + w, ::\n",
    "                ] += 1\n",
    "\n",
    "    # Cut to a 40x40 window\n",
    "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
    "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
    "    noisy_movies = np.clip(\n",
    "        noisy_movies, 0.0, 1.0\n",
    "    )  # noisy_movies[noisy_movies >= 1] = 255\n",
    "    shifted_movies = np.clip(shifted_movies, 0.0, 1.0)\n",
    "    return noisy_movies, shifted_movies, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c05e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_movies, shifted_movies, Y = generate_movies(n_samples=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fe5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(noisy_movies.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a651546",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def get_label(y):\n",
    "    label = []\n",
    "\n",
    "    if y[0] > 0.6:\n",
    "        label.append(\"UP\")\n",
    "    if y[1] > 0.6:\n",
    "        label.append(\"DOWN\")\n",
    "    if y[2] > 0.6:\n",
    "        label.append(\"LEFT\")\n",
    "    if y[3] > 0.6:\n",
    "        label.append(\"RIGHT\")\n",
    "\n",
    "    if len(label) == 0:\n",
    "        label.append(\"STILL\")\n",
    "\n",
    "    return \" \".join(label)\n",
    "\n",
    "\n",
    "def show_prediction(X, y, model, ax):\n",
    "\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "\n",
    "    # Get movie info\n",
    "    title = get_label(y)\n",
    "\n",
    "    # Generate prediction\n",
    "    prediction = model.predict(X)\n",
    "\n",
    "    title += \"vs \" + get_label(prediction[0])\n",
    "\n",
    "    # Dispaly image with prediction\n",
    "    style.use(\"default\")\n",
    "    # plt.figure(figsize=(8,4))\n",
    "    # plt.title(title, fontsize=9)\n",
    "\n",
    "    frame = 0\n",
    "    im = ax.imshow(movie[frame])\n",
    "\n",
    "    # ax.close() # this is required to not display the generated image\n",
    "\n",
    "    def init():\n",
    "        im.set_data(movie[0, :, :, :])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(movie[i, :, :, :])\n",
    "        return im\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        ax, animate, init_func=init, frames=movie.shape[0], interval=50\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af3cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(nrows, ncols, X, Y, model=None):\n",
    "\n",
    "    plt.xkcd()\n",
    "\n",
    "    # See https://matplotlib.org/stable/tutorials/introductory/customizing.html\n",
    "\n",
    "    plt.rcParams[\"xtick.bottom\"] = False\n",
    "    plt.rcParams[\"ytick.left\"] = False\n",
    "    plt.rcParams[\"xtick.labelbottom\"] = False\n",
    "    plt.rcParams[\"ytick.labelleft\"] = False\n",
    "\n",
    "    # fig = plt.figure()\n",
    "    # fig.suptitle(label)\n",
    "\n",
    "    maxi = X.max()\n",
    "    mini = X.min()\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "\n",
    "    axs = np.array(axs)\n",
    "\n",
    "    movies = []\n",
    "\n",
    "    if model != None:\n",
    "        Y_hat = model.predict(X[::, ::, ::, ::, ::])\n",
    "\n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        im = ax.imshow(X[i, 0, ::, ::, ::])\n",
    "        label = get_label(Y[i])\n",
    "        if model != None:\n",
    "            label += (\n",
    "                \" vs \"\n",
    "                + get_label(Y_hat[i])\n",
    "                + \"\\n[{:.2f},{:.2f},{:.2f},{:.2f}]\".format(\n",
    "                    Y_hat[i, 0], Y_hat[i, 1], Y_hat[i, 2], Y_hat[i, 3]\n",
    "                )\n",
    "            )\n",
    "        ax.set_title(label, fontsize=9)\n",
    "        movies.append(im)\n",
    "\n",
    "    def animate(frame):\n",
    "        for i, ax in enumerate(axs.reshape(-1)):\n",
    "            movies[i].set_data(X[i, frame, ::, ::, ::])\n",
    "\n",
    "        return movies\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, blit=True, frames=X.shape[1], repeat=True, interval=100\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2055ca",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 15\n",
    "img_height = 40\n",
    "img_width = 40\n",
    "\n",
    "classes = [\"up\", \"down\", \"left\", \"right\"]\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    layers.ConvLSTM2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        return_sequences=False,\n",
    "        data_format=\"channels_last\",\n",
    "        input_shape=noisy_movies.shape[1:],\n",
    "    )\n",
    ")\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(4, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff341fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    noisy_movies, Y, test_size=0.20, shuffle=True, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a71ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "ind = np.random.randint(0, high=X_train.shape[0], size=nrows * ncols)\n",
    "\n",
    "anim = display(nrows, ncols, X_train[ind, ::, ::, ::, ::], y_train[ind, ::], model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_soft_f1(y, y_hat):\n",
    "    \"\"\"Compute the macro soft F1-score as a cost (average 1 - soft-F1 across all labels).\n",
    "    Use probability values instead of binary predictions.\n",
    "\n",
    "    Args:\n",
    "        y (int32 Tensor): targets array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "\n",
    "    Returns:\n",
    "        cost (scalar Tensor): value of the cost function for the batch\n",
    "    \"\"\"\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    y_hat = tf.cast(y_hat, tf.float32)\n",
    "    tp = tf.reduce_sum(y_hat * y, axis=0)\n",
    "    fp = tf.reduce_sum(y_hat * (1 - y), axis=0)\n",
    "    fn = tf.reduce_sum((1 - y_hat) * y, axis=0)\n",
    "    soft_f1 = 2 * tp / (2 * tp + fn + fp + 1e-16)\n",
    "    cost = 1 - soft_f1  # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "    macro_cost = tf.reduce_mean(cost)  # average on all labels\n",
    "    return macro_cost  # Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ec1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def macro_f1(y, y_hat, thresh=0.6):\n",
    "    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n",
    "\n",
    "    Args:\n",
    "        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n",
    "        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n",
    "        thresh: probability value above which we predict positive\n",
    "\n",
    "    Returns:\n",
    "        macro_f1 (scalar Tensor): value of macro F1 for the batch\n",
    "    \"\"\"\n",
    "    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n",
    "    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n",
    "    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n",
    "    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n",
    "    f1 = 2 * tp / (2 * tp + fn + fp + 1e-16)\n",
    "    macro_f1 = tf.reduce_mean(f1)\n",
    "    return macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b881b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(loss=macro_soft_f1, optimizer=opt, metrics=[macro_f1])\n",
    "\n",
    "earlystop = EarlyStopping(patience=7)\n",
    "callbacks = [earlystop]\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=40,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039d8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curves(history):\n",
    "    \"\"\"Plot the learning curves of loss and macro f1 score\n",
    "    for the training and validation datasets.\n",
    "\n",
    "    Args:\n",
    "        history: history callback of fitting a tensorflow keras model\n",
    "    \"\"\"\n",
    "\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    macro_f1 = history.history[\"macro_f1\"]\n",
    "    val_macro_f1 = history.history[\"val_macro_f1\"]\n",
    "\n",
    "    epochs = len(loss)\n",
    "\n",
    "    style.use(\"bmh\")\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    plt.rcParams[\"xtick.bottom\"] = True\n",
    "    plt.rcParams[\"ytick.left\"] = True\n",
    "    plt.rcParams[\"xtick.labelbottom\"] = True\n",
    "    plt.rcParams[\"ytick.labelleft\"] = True\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(range(1, epochs + 1), loss, label=\"Training Loss\")\n",
    "    plt.plot(range(1, epochs + 1), val_loss, label=\"Validation Loss\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(range(1, epochs + 1), macro_f1, label=\"Training Macro F1-score\")\n",
    "    plt.plot(range(1, epochs + 1), val_macro_f1, label=\"Validation Macro F1-score\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.ylabel(\"Macro F1-score\")\n",
    "    plt.title(\"Training and Validation Macro F1-score\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return loss, val_loss, macro_f1, val_macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f4a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772d36c",
   "metadata": {},
   "source": [
    "# See predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 3\n",
    "ncols = 2\n",
    "\n",
    "ind = np.random.randint(0, high=X_test.shape[0], size=nrows * ncols)\n",
    "\n",
    "anim_test = display(\n",
    "    nrows, ncols, X_test[ind, ::, ::, ::, ::], y_test[ind, ::], model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim_test.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
