{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37744891",
   "metadata": {},
   "source": [
    "# Image Denoising Challenge\n",
    "\n",
    "The goal for this challenge is to leverage your knowledge of Deep Learning to design and train a denoising model. For a given noisy image $X$, our model should learn to predict the denoised image $y$.\n",
    "\n",
    "\n",
    "**Objectives**\n",
    "- Visualize images\n",
    "- Preprocess images for the neural network\n",
    "- Fit a custom CNN for the task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d0b0e",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "üëâ Let's download the dataset archive.\n",
    "It contains RGB and Black & White images we will be using for the rest of this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e468dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.120990Z",
     "start_time": "2021-06-30T10:09:55.663971Z"
    }
   },
   "outputs": [],
   "source": [
    "! rm -rf paintings/\n",
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/paintings.zip > paintings.zip\n",
    "! LANG=en_US.UTF-8 unzip -nq \"paintings.zip\" \n",
    "! rm \"paintings.zip\"\n",
    "! ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab995a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.193336Z",
     "start_time": "2021-06-30T10:11:24.147460Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "dataset_paths = glob.glob(\"./paintings/*.jpg\")\n",
    "print(f\"The dataset contains {len(dataset_paths)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dd613d",
   "metadata": {},
   "source": [
    "‚ùì **Display the image at index `53` of this dataset_paths (i.e the 54-th image)**\n",
    "\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    Use the <code>PIL.Image.open</code> and <code>matplotlib.pyplot.imshow</code> functions.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd91f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.893469Z",
     "start_time": "2021-06-30T10:11:24.251953Z"
    },
    "scrolled": false,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# get the path of the image at index 53\n",
    "path_53 = dataset_paths[53]\n",
    "\n",
    "# open the image \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with Image.open(path_53) as im:\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1876cbb6",
   "metadata": {},
   "source": [
    "‚ùì **What is the shape of the image you displayed above `img_shape`?  How many dimensions `img_dim` does it have ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8eb466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.925639Z",
     "start_time": "2021-06-30T10:11:24.919224Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# shape of the image \n",
    "image = Image.open(path_53)\n",
    "# size is given (width, height)\n",
    "image.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65034f13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.963199Z",
     "start_time": "2021-06-30T10:11:24.951420Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set seed so that results are reproduceable\n",
    "np.random.seed(42)\n",
    "\n",
    "np_image = np.array(im)\n",
    "# (row, col, depth)\n",
    "np_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dccee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:24.999773Z",
     "start_time": "2021-06-30T10:11:24.996260Z"
    }
   },
   "outputs": [],
   "source": [
    "# as it is a colourful image -> 3 dimensions for RGB\n",
    "img_dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31d38f",
   "metadata": {},
   "source": [
    "‚ùì **What was in the image above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0e975",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:25.033573Z",
     "start_time": "2021-06-30T10:11:25.028686Z"
    }
   },
   "outputs": [],
   "source": [
    "img_shape = np_image.shape\n",
    "img_dim = img_dim\n",
    "\n",
    "#is_portrait = True\n",
    "is_portrait = False\n",
    "\n",
    "is_colored_image = True\n",
    "#is_colored_image = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae18df9",
   "metadata": {},
   "source": [
    "## 2. Look for duplicates\n",
    "\n",
    "üëâ Let's check if we have similar images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "class Hasher:\n",
    "    def __init__(self, verbose: bool = False) -> None:\n",
    "        self.target_size = (32, 32)\n",
    "        self.__coefficient_extract = (8, 8)\n",
    "        self.verbose = verbose\n",
    "        self.query_results_map = None\n",
    "\n",
    "    @staticmethod\n",
    "    def hamming_distance(hash1: str, hash2: str) -> float:\n",
    "        hash1_bin = bin(int(hash1, 16))[2:].zfill(64)\n",
    "        hash2_bin = bin(int(hash2, 16))[2:].zfill(64)\n",
    "        return np.sum([i != j for i, j in zip(hash1_bin, hash2_bin)])\n",
    "    \n",
    "    def encode_image(self, image_file=None) -> str:\n",
    "        try:\n",
    "            if image_file and os.path.exists(image_file):\n",
    "                image_file = Path(image_file)\n",
    "                img = Image.open(image_file)\n",
    "    \n",
    "                if img.format not in ['JPEG', 'PNG', 'BMP', 'MPO', 'PPM', 'TIFF', 'GIF']:\n",
    "                    return None\n",
    "    \n",
    "                if img.mode != 'RGB':\n",
    "                    # convert to RGBA first to avoid warning\n",
    "                    # we ignore alpha channel if available\n",
    "                    img = img.convert('RGBA').convert('RGB')\n",
    "                    \n",
    "                \n",
    "                image_pp = np.array(img.resize(self.target_size, Image.ANTIALIAS).convert('L')).astype('uint8')\n",
    "            else:\n",
    "                raise ValueError\n",
    "        except (ValueError, TypeError):\n",
    "            raise ValueError('Please provide either image file path')\n",
    "\n",
    "        return self._hash_func(image_pp) if isinstance(image_pp, np.ndarray) else None\n",
    "    \n",
    "    def encode_images(self, image_dir=None) -> Dict[str, str]:\n",
    "        if not os.path.isdir(image_dir):\n",
    "            raise ValueError('Please provide a valid directory path!')\n",
    "\n",
    "        image_dir = Path(image_dir)\n",
    "\n",
    "        files = [\n",
    "            i.absolute() for i in image_dir.glob('*') if not i.name.startswith('.')\n",
    "        ]  # ignore hidden files\n",
    "        \n",
    "        #pool = Pool(processes=cpu_count())\n",
    "        #hashes = list(\n",
    "        #    tqdm.tqdm(pool.imap(self.encode_image, files, 100), total=len(files), disable=not self.verbose)\n",
    "        #)\n",
    "        #pool.close()\n",
    "        #pool.join()\n",
    "        \n",
    "        hashes = [self.encode_image(f) for f in files]\n",
    "        \n",
    "        hash_initial_dict = dict(zip([f.name for f in files], hashes))\n",
    "        hash_dict = {\n",
    "            k: v for k, v in hash_initial_dict.items() if v\n",
    "        }  # To ignore None (returned if some probelm with image file)\n",
    "\n",
    "        return hash_dict\n",
    "    \n",
    "    def _hash_func(self, image_array: np.ndarray) -> str:\n",
    "        dct_coef = dct(dct(image_array, axis=0), axis=1)\n",
    "\n",
    "        # retain top left 8 by 8 dct coefficients\n",
    "        dct_reduced_coef = dct_coef[: self.__coefficient_extract[0], : self.__coefficient_extract[1]]\n",
    "\n",
    "        # median of coefficients excluding the DC term (0th term)\n",
    "        median_coef_val = np.median(np.ndarray.flatten(dct_reduced_coef)[1:])\n",
    "\n",
    "        # return mask of all coefficients greater than mean of coefficients\n",
    "        hash_mat = dct_reduced_coef >= median_coef_val\n",
    "        \n",
    "        return ''.join('%0.2x' % x for x in np.packbits(hash_mat))\n",
    "    \n",
    "    def find_duplicates(self, image_dir: str = None, encoding_map: List[str] = None, threshold: int = 10) -> Dict:\n",
    "        if not encoding_map:\n",
    "            encoding_map = self.encode_images(image_dir)\n",
    "            \n",
    "        result_map = defaultdict(list)\n",
    "\n",
    "        for i, (ki, vi) in enumerate(encoding_map.items()):\n",
    "            for j, (kj, vj) in enumerate(encoding_map.items()):\n",
    "                if i < j:\n",
    "                    dij = self.hamming_distance(vi, vj)\n",
    "                    if dij <= threshold:\n",
    "                        result_map[ki].append((kj, dij))\n",
    "                        result_map[kj].append((ki, dij))\n",
    "        \n",
    "        self.query_results_map = {\n",
    "            k: [i for i in sorted(v, key=lambda tup: tup[1], reverse=False)]\n",
    "            for k, v in result_map.items()\n",
    "        }\n",
    "                \n",
    "        return self.query_results_map\n",
    "    \n",
    "    def get_files_to_remove(self, duplicates: Dict[str, List] = None) -> List:\n",
    "        files_to_remove = set()\n",
    "        \n",
    "        for k, v in duplicates.items():\n",
    "            tmp = [i[0] for i in v]\n",
    "            \n",
    "            if k not in files_to_remove:\n",
    "                files_to_remove.update(tmp)\n",
    "                \n",
    "        return list(files_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a63f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hasher = Hasher()\n",
    "encodings = hasher.encode_images('paintings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4517fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = hasher.find_duplicates(encoding_map=encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6711c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "image_dir = 'paintings'\n",
    "\n",
    "for original, image_list in duplicates.items():    \n",
    "    n_images = len(image_list)\n",
    "    ncols = 4  # fixed for a consistent layout\n",
    "    nrows = int(np.ceil(n_images / ncols)) + 1\n",
    "    fig = plt.Figure(figsize=(10, 14))\n",
    "\n",
    "    gs = gridspec.GridSpec(nrows=nrows, ncols=ncols)\n",
    "    ax = plt.subplot(gs[0, 1:3])  # Always plot the original image in the middle of top row\n",
    "    ax.imshow(Image.open(f\"{image_dir}/{original}\"))\n",
    "    ax.set_title(f\"Original Image: {original}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    for i in range(0, n_images):\n",
    "        row_num = (i // ncols) + 1\n",
    "        col_num = i % ncols\n",
    "\n",
    "        ax = plt.subplot(gs[row_num, col_num])\n",
    "        ax.imshow(Image.open(f\"{image_dir}/{image_list[i][0]}\"))\n",
    "        title = ' '.join([image_list[i][0], f\"({image_list[i][1]})\"])\n",
    "        ax.set_title(title, fontsize=9)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d48195",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher.get_files_to_remove(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e288509",
   "metadata": {},
   "source": [
    "## 3. Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a140c68",
   "metadata": {},
   "source": [
    "‚ùì **Store all images from the dataset folder in a list of numpy arrays called `dataset_images`**\n",
    "\n",
    "- It can take a while\n",
    "- If the dataset is too big to fit in memory, just take the first half (or quarter) of all pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec89764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:34.153900Z",
     "start_time": "2021-06-30T10:11:25.151841Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "dataset_images = []\n",
    "\n",
    "for img_name in dataset_paths:\n",
    "    image = Image.open(img_name)\n",
    "    dataset_images.append(np.array(image))\n",
    "    \n",
    "print(type(dataset_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db741ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:11:35.665532Z",
     "start_time": "2021-06-30T10:11:35.660807Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(dataset_images), dataset_images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e7e62",
   "metadata": {},
   "source": [
    "### 3.1 Reshape, Resize, Rescale\n",
    "\n",
    "Let's simplify our dataset and convert it to a single numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a315e1a",
   "metadata": {},
   "source": [
    "‚ùì **First, check if that all the images in the dataset have the same number of dimensions**.\n",
    "- What do you notice?\n",
    "- How do you explain it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e700a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:15:50.594071Z",
     "start_time": "2021-06-30T10:15:50.587141Z"
    }
   },
   "outputs": [],
   "source": [
    "dim1, dim2, dim3 = [], [], []\n",
    "for img in dataset_images:\n",
    "    shap = img.shape\n",
    "    dim1.append(shap[0])\n",
    "    dim2.append(shap[1])\n",
    "    if len(shap) > 2:\n",
    "        dim3.append(shap[2])\n",
    "        \n",
    "if len(dim3) == len(dim2):\n",
    "    print(\"All images are RGB\")\n",
    "else:\n",
    "    print(\"Some images are B&W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b60b6d",
   "metadata": {},
   "source": [
    "üëâ We convert for you all black & white images into 3-colored ones by duplicating the image on three channels, so as to have only 3D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef5d1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:16:09.187061Z",
     "start_time": "2021-06-30T10:16:07.689599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "dataset_images = [x if x.ndim == 3 else np.repeat(x[:,:,None], 3, axis=2) for x in tqdm(dataset_images)]\n",
    "\n",
    "# Print the set of the number of dimensions of all arrays (it should contain only the value 3)\n",
    "set([x.ndim for x in dataset_images])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34d7d7",
   "metadata": {},
   "source": [
    "‚ùì **What about their shape now ?**\n",
    "- Do they all have the same width/heights ? If not:\n",
    "- Resize the images (120 pixels height and 100 pixels width) in the dataset, using `tensorflow.image.resize` function.\n",
    "- Now that they all have the same shape, store them as a numpy array `dataset_resized`.\n",
    "- This array should thus be of size $(n_{images}, 120, 100, 3)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7edd8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:16:10.906539Z",
     "start_time": "2021-06-30T10:16:10.900705Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "if len(set(dim1)) == 1 and len(set(dim2)) == 1:\n",
    "    print(\"Images dont have all the same size\")\n",
    "else:\n",
    "    print(\"Images dont have the same size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe158aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:16:14.726140Z",
     "start_time": "2021-06-30T10:16:14.714685Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"[height]\", \"max:\", max(dim1), \"min:\", min(dim1))\n",
    "print(\"[width] \", \"max:\", max(dim2), \"min:\", min(dim2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cf09b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:16:21.316878Z",
     "start_time": "2021-06-30T10:16:16.640060Z"
    }
   },
   "outputs": [],
   "source": [
    "# resizing \n",
    "from tensorflow.image import resize, rgb_to_grayscale, image_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ff6f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:16:32.248919Z",
     "start_time": "2021-06-30T10:16:32.019599Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# resizing all\n",
    "\n",
    "resized_img = []\n",
    "\n",
    "for img in dataset_images:\n",
    "    resized_img.append(resize(img, (120, 100), antialias=True).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837efb21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:38:15.045877Z",
     "start_time": "2021-06-30T10:16:44.994771Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_resized = np.array(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ec092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:38:17.762648Z",
     "start_time": "2021-06-30T10:38:17.757231Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad5ff7",
   "metadata": {},
   "source": [
    "‚ùì **Rescale the data of each image between $0$ and $1$**\n",
    "- Save your resulting list as `dataset_scaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255087e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:48:43.496482Z",
     "start_time": "2021-06-30T10:48:43.448421Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "print(np.max(dataset_resized), np.min(dataset_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bfd462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:55:55.239642Z",
     "start_time": "2021-06-30T10:55:55.174256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's divide by 255 \n",
    "\n",
    "dataset_scaled = dataset_resized / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367bc23d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:56:22.005592Z",
     "start_time": "2021-06-30T10:56:21.990961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check the max and mean:\n",
    "print(np.min(dataset_scaled), np.max(dataset_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bcba81",
   "metadata": {},
   "source": [
    "### 3.2 Create (X, y) sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433bfb7e",
   "metadata": {},
   "source": [
    "üëâ Now, we'll add for you some **random noise** to our images to simulate noise (that our model will try to remove later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71c20c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T10:56:29.550315Z",
     "start_time": "2021-06-30T10:56:29.030547Z"
    }
   },
   "outputs": [],
   "source": [
    "NOISE_LEVEL = 0.2\n",
    "\n",
    "# Compute Gaussian noise\n",
    "mean = 0\n",
    "var = 0.1\n",
    "sigma = var**0.5\n",
    "noise = NOISE_LEVEL*np.random.normal(mean, sigma, size=dataset_scaled.shape)\n",
    "\n",
    "# There are other types of noise: poisson, speckle, salt_n_pepper\n",
    "\n",
    "print(type(noise), noise.shape, noise.dtype)\n",
    "dataset_noisy = dataset_scaled + noise\n",
    "\n",
    "# Images data can now be in [-0.2, 1.2]\n",
    "print(f\"Before clipping: [{np.min(dataset_noisy)}, {np.max(dataset_noisy)}]\")\n",
    "\n",
    "dataset_noisy = np.clip(dataset_noisy, 0, 1)\n",
    "print(f\"After clipping: [{np.min(dataset_noisy), np.max(dataset_noisy)}]\")\n",
    "\n",
    "dataset_noisy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fbd008",
   "metadata": {},
   "source": [
    "‚ùì **Plot a noisy image below to visualize the noise and compare it with the normal one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629856c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:00:07.459002Z",
     "start_time": "2021-06-30T11:00:03.965184Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "for i, (scaled_image, noisy_image) in enumerate(zip(dataset_scaled, dataset_noisy)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "    ax1.imshow(scaled_image)\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(noisy_image)\n",
    "    ax2.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfcfb0",
   "metadata": {},
   "source": [
    "‚ùì **Create your `(X_train, Y_train)`, `(X_test, Y_test)` training set for your problem**\n",
    "\n",
    "- Remember you are trying to use \"noisy\" pictures in order to predict the \"normal\" ones.\n",
    "- Keeping about `20%` of randomly sampled data as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c7a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:02:43.676944Z",
     "start_time": "2021-06-30T11:02:43.609431Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dataset_noisy\n",
    "y = dataset_scaled\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b846231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:02:46.793054Z",
     "start_time": "2021-06-30T11:02:46.744527Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, Y_train.shape, X_train[:,:,:,0].std(), Y_train[:,:,:,0].std())\n",
    "# Y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd012291",
   "metadata": {},
   "source": [
    "## 4. Convolutional Neural Network\n",
    "\n",
    "A commonly used neural network architecture for image denoising is the __AutoEncoder__.\n",
    "\n",
    "<img src='https://github.com/lewagon/data-images/blob/master/DL/autoencoder.png?raw=true'>\n",
    "\n",
    "Its goal is to learn a compact representation of your data to reconstruct them as precisely as possible.  \n",
    "The loss for such model must incentivize it to have __an output as close to the input as possible__.\n",
    "\n",
    "For this challenge, __you will only be asked to code the Encoder part of the network__, since building a Decoder leverages layers architectures you are not familiar with (yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f7ee6",
   "metadata": {},
   "source": [
    "üëâ Run this code below if you haven't managed to build your own (X,Y) training sets. This will load them as solution\n",
    "\n",
    "```python\n",
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "import pickle\n",
    "with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "    (X_train, Y_train, X_test, Y_test) = pickle.load(file)\n",
    "    \n",
    "! rm data_painting_solution.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ec696",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:09:01.889540Z",
     "start_time": "2021-06-30T11:03:43.818544Z"
    }
   },
   "outputs": [],
   "source": [
    "! curl https://wagon-public-datasets.s3.amazonaws.com/certification_france_2021_q2/data_painting_solution.pickle > data_painting_solution.pickle\n",
    "\n",
    "import pickle\n",
    "with open(\"data_painting_solution.pickle\", \"rb\") as file:\n",
    "    (X_train_ref, Y_train_ref, X_test_ref, Y_test_ref) = pickle.load(file)\n",
    "\n",
    "! rm data_painting_solution.pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcebc6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_display = [[50, 50], [62, 110], [228, 207], [187, 322], [238, 8]]\n",
    "\n",
    "for i, pair in enumerate(to_display):\n",
    "    _, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20, 20))\n",
    "    ax1.imshow(Y_train[pair[0]])\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(Y_train_ref[pair[1]])\n",
    "    ax2.axis('off')\n",
    "    ax3.imshow(Y_train[pair[0]]-Y_train_ref[pair[1]])\n",
    "    ax3.axis('off')\n",
    "    ax4.imshow(X_train[pair[0]])\n",
    "    ax4.axis('off')\n",
    "    ax5.imshow(X_train_ref[pair[1]])\n",
    "    ax5.axis('off')\n",
    "    print(f\"{np.sum(Y_train[pair[0]]-Y_train_ref[pair[1]])} - {X_train[pair[0],:, :, 0].std()} vs {X_train_ref[pair[1],:, :, 0].std()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c66399",
   "metadata": {},
   "source": [
    "### 4.1 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e244a",
   "metadata": {},
   "source": [
    "üëâ Run the cell below that defines the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd0d6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:09:05.962684Z",
     "start_time": "2021-06-30T11:09:05.958151Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6855a520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T11:09:09.123367Z",
     "start_time": "2021-06-30T11:09:08.850335Z"
    }
   },
   "outputs": [],
   "source": [
    "# We choose to compress images into a latent_dimension of size 6000\n",
    "latent_dimensions = 6000\n",
    "\n",
    "# We build a decoder that takes 1D-vectors of size 6000 to reconstruct images of shape (120,100,3)\n",
    "decoder = Sequential(name='decoder')\n",
    "decoder.add(layers.Reshape((30, 25, 8), input_dim=latent_dimensions))\n",
    "decoder.add(layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding=\"same\", activation=\"relu\"))\n",
    "decoder.add(layers.Conv2D(filters=3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f497ffa",
   "metadata": {},
   "source": [
    "‚ùì **Now, build the `encoder` that plugs correctly with the decoder defined above**. Make sure that:\n",
    "- The output of your `encoder` is the same shape as the input of the `decoder`\n",
    "- Use a convolutional neural network architecture without transfer learning\n",
    "- Keep it simple\n",
    "- Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba2fcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:12:24.015505Z",
     "start_time": "2021-06-30T15:12:23.993533Z"
    }
   },
   "outputs": [],
   "source": [
    "# CODE HERE YOUR ENCODER ARCHITECTURE AND PRINT IT'S MODEL SUMMARY\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "def build_encoder(latent_dimension):\n",
    "    encoder = Sequential(name=\"encoder\")\n",
    "    encoder.add(layers.InputLayer(input_shape=(120, 100, 3)))\n",
    "    encoder.add(layers.Conv2D(32, 5, strides=2, padding='same', activation=layers.LeakyReLU(0.1)))\n",
    "    encoder.add(layers.Dropout(0.2))\n",
    "    encoder.add(layers.Conv2D(8, 3, strides=2, padding='same', activation=layers.LeakyReLU(0.1)))\n",
    "    encoder.add(layers.Dropout(0.3))\n",
    "    encoder.add(layers.Flatten())\n",
    "    # encoder.add(Dense(latent_dimension, activation='sigmoid'))\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f682b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:12:34.036853Z",
     "start_time": "2021-06-30T15:12:33.359432Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = build_encoder(6000)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec2cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T09:32:05.702398Z",
     "start_time": "2021-06-22T09:32:05.696251Z"
    }
   },
   "source": [
    "üëâ **Test your encoder below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd12432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:12:42.722524Z",
     "start_time": "2021-06-30T15:12:42.647157Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HERE WE BUILD THE AUTO-ENCODER (ENCODER + DECODER) FOR YOU. IT SHOULD PRINT A NICE SUMMARY\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "x = layers.Input(shape=(120, 100, 3))\n",
    "autoencoder = Model(x, decoder(encoder(x)), name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b4e034",
   "metadata": {},
   "source": [
    "### 4.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34034ac",
   "metadata": {},
   "source": [
    "‚ùì **Before training the autoencoder, evaluate your baseline score**\n",
    "- We will use the mean absolute error in this challenge\n",
    "- Compute the baseline score on your test set in the \"stupid\" case where you don't manage to de-noise anything at all.\n",
    "- Store the result under `score_baseline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128449e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:44:45.463714Z",
     "start_time": "2021-06-30T15:44:45.402162Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import tensorflow as tf\n",
    "\n",
    "# Baseline: we predict the noisy image\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Baseline, self).__init__()\n",
    "        \n",
    "    def call(self, x):\n",
    "        return x\n",
    "\n",
    "baseline = Baseline()\n",
    "\n",
    "baseline.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# An other way to do it !\n",
    "# print(tf.keras.metrics.mean_absolute_error(Y_test, X_test).numpy().mean())\n",
    "\n",
    "score_baseline = baseline.evaluate(X_test, Y_test)\n",
    "score_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecb73d",
   "metadata": {},
   "source": [
    "‚ùì Now, **train your autoencoder**\n",
    "\n",
    "- Use an appropriate loss\n",
    "- Adapt the learning rate of your optimizer if convergence is too slow/fast\n",
    "- Make sure your model does not overfit with appropriate control techniques\n",
    "\n",
    "üí° You will not be judged by the computing power of your computer, you can reach decent performance in less than 5 minutes of training without GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b352e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:48:20.932415Z",
     "start_time": "2021-06-30T15:48:20.917712Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_autoencoder(autoencoder):\n",
    "    autoencoder.compile(loss='mae', optimizer=tf.optimizers.Adam(0.0005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff44c49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:57:36.372484Z",
     "start_time": "2021-06-30T15:54:17.891458Z"
    },
    "scrolled": true,
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE \n",
    "\n",
    "# Attention no metric is define \n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, verbose=1, restore_best_weights=True)\n",
    "\n",
    "compile_autoencoder(autoencoder)\n",
    "\n",
    "history_denoising = autoencoder.fit(X_train, Y_train, \n",
    "                                    validation_split=0.2, epochs=1000,\n",
    "                                    shuffle = True,\n",
    "                                    batch_size=32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15566948",
   "metadata": {},
   "source": [
    "‚ùì **Plot your training and validation loss at each epoch using the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12101fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:58:06.953610Z",
     "start_time": "2021-06-30T15:58:06.564736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot below your train/val loss history\n",
    "# YOUR CODE HERE\n",
    "\n",
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    f = plt.figure(figsize=(10,7))\n",
    "    f.add_subplot()\n",
    "\n",
    "    #Adding Subplot\n",
    "    plt.plot(history.epoch, history.history['loss'], label = \"loss\") # Loss curve for training set\n",
    "    plt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\") # Loss curve for validation set\n",
    "\n",
    "    plt.title(\"Loss Curve\",fontsize=18)\n",
    "    plt.xlabel(\"Epochs\",fontsize=15)\n",
    "    plt.ylabel(\"Loss\",fontsize=15)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"Loss_curve.png\")\n",
    "    return f\n",
    "\n",
    "plot_history(history_denoising)\n",
    "\n",
    "\n",
    "# Run also this code to save figure as jpg in path below (it's your job to ensure it works)\n",
    "fig = plt.gcf()\n",
    "plt.savefig(\"history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9101b81d",
   "metadata": {},
   "source": [
    "‚ùì **Evaluate your performances on test set**\n",
    "- Compute your de-noised test set `Y_pred` \n",
    "- Store your test score as `score_test`\n",
    "- Plot a de-noised image from your test set and compare it with the original and noisy one using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1003f92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:33:23.147732Z",
     "start_time": "2021-06-23T10:33:22.679613Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "score_test = autoencoder.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905b54f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:34:10.656669Z",
     "start_time": "2021-06-23T10:34:10.159522Z"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO CHECK YOUR RESULTS\n",
    "\n",
    "Y_pred = autoencoder.predict(X_test)\n",
    "\n",
    "l = np.arange(len(X_test))\n",
    "np.random.shuffle(l)\n",
    "\n",
    "for i in l[:5]:\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10,5))\n",
    "    ax1.imshow(Y_test[i])\n",
    "    ax1.set_title(\"Clean image.\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(X_test[i])\n",
    "    ax2.set_title(\"Noisy image.\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.imshow(Y_pred[i])\n",
    "    ax3.set_title(\"Prediction.\")\n",
    "    ax3.axis('off')\n",
    "\n",
    "# Run this to save your results for correction\n",
    "plt.savefig('image_denoised.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ce3a2",
   "metadata": {},
   "source": [
    "## 5. Other stuff (Data Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be75e3",
   "metadata": {},
   "source": [
    "### 5.1 Use dataset from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tf.data.Dataset.from_tensor_slices(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba5ae3",
   "metadata": {},
   "source": [
    "### 5.2 Use dataset from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be681fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob('paintings/*.jpg')\n",
    "\n",
    "n_full = len(list_files)\n",
    "\n",
    "n_train = int(0.7*n_full)\n",
    "n_test = int(0.15*n_full)\n",
    "n_val = n_full - n_train - n_test\n",
    "\n",
    "print(f\"n_train: {n_train} - n_val: {n_val} - n_test: {n_test}\")\n",
    "\n",
    "ds_full = tf.data.Dataset.from_tensor_slices((list_files, list_files)).shuffle(n_full, reshuffle_each_iteration=False)\n",
    "ds_train = ds_full.take(n_train)\n",
    "ds_test = ds_full.skip(n_train)\n",
    "ds_val = ds_test.skip(n_val)\n",
    "ds_test = ds_test.take(n_test)\n",
    "\n",
    "def load(file_path, add_noise=False):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, size=(120, 100), antialias=True)\n",
    "    if add_noise:\n",
    "        img += 0.2*tf.random.normal((120, 100, 3), stddev=0.316, dtype=tf.dtypes.float32)\n",
    "    img = tf.clip_by_value(img, 0, 1)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def process_image(file_path1, file_path2):\n",
    "    img = tf.stack([load(file_path1), load(file_path2, add_noise=True)])\n",
    "    choice = tf.random.uniform((), minval=0, maxval=1)\n",
    "    if choice < 0.5:\n",
    "        img = tf.image.random_hue(img, max_delta=.5)\n",
    "    choice = tf.random.uniform((), minval=0, maxval=1)\n",
    "    if choice < 0.5:\n",
    "        img =  tf.image.flip_left_right(img)\n",
    "    choice = tf.random.uniform((), minval=0, maxval=1)\n",
    "    if choice < 0.5:\n",
    "        img =  tf.image.flip_up_down(img)\n",
    "\n",
    "    return img[0], img[1]\n",
    "\n",
    "ds_train = ds_train.map(lambda x, y: process_image(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(n_train).batch(64).prefetch(2)\n",
    "ds_val = ds_val.map(lambda x, y: process_image(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(n_val).batch(64)\n",
    "ds_test = ds_test.map(lambda x, y: process_image(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(64)\n",
    "\n",
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "for (x, y) in ds_train.take(5):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    print(np.min(x[0, ...]), np.max(x[0, ...]), np.min(y[0, ...]), np.max(y[0, ...]))\n",
    "    ax1.imshow(x[0, ...])\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(y[0, ...])\n",
    "    ax2.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cd9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 6000 \n",
    "\n",
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.InputLayer(input_shape=(120, 100, 3)),\n",
    "            tf.keras.layers.Conv2D(32, 5, strides=2, padding='same', activation=layers.LeakyReLU(0.1)),\n",
    "            tf.keras.layers.Dropout(0.2),\n",
    "            tf.keras.layers.Conv2D(8, 3, strides=2, padding='same', activation=layers.LeakyReLU(0.1)),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Flatten(),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([        \n",
    "            tf.keras.layers.Reshape((30, 25, 8), input_dim=self.latent_dim),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu'),\n",
    "            tf.keras.layers.Conv2D(filters=3, kernel_size=3, padding='same', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d6bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanAbsoluteError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=25, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# reduce learning rate when on a plateau\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=10, min_delta=0.0001, factor=0.2,)\n",
    "\n",
    "history = autoencoder.fit(ds_train, epochs=1_000, shuffle=True, validation_data=ds_val, callbacks=[es, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ba29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4955a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.evaluate(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da719ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_iter = ds_test.make_one_shot_iterator()\n",
    "\n",
    "i = 0\n",
    "for (x, y) in ds_test_iter.get_next():\n",
    "    _, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    ax1.imshow(y[0, ...])\n",
    "    ax1.set_title(\"Clean image.\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    ax2.imshow(x[0, ...])\n",
    "    ax2.set_title(\"Noisy image.\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    y_pred = autoencoder.predict(x)\n",
    "\n",
    "    ax3.imshow(y_pred[i])\n",
    "    ax3.set_title(\"Prediction.\")\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    \n",
    "\n",
    "    i = i + 1\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519999e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
